{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.6/site-packages (1.5.1)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /opt/conda/lib/python3.6/site-packages (from sacrebleu) (2.0.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (1.6.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch) (1.19.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.95)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install sacrebleu\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "!pip install sentencepiece\n",
    "import sentencepiece as spm\n",
    "from utils import *\n",
    "from collections import Counter\n",
    "from transformer_model import Transformer as Trans_model\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sami_model = \"combbigbpe.model\"\n",
    "swedish_model = \"combbigbpe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"bpe_joint_2layer_gelu.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sami_sent, swedish_sent = read_data('corpora/smeswebig.tmx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227106"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sami_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spm.SentencePieceTrainer.Train('--input=combinedbig.txt --model_prefix=combbigbpe --vocab_size=16000 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[<PAD>] --unk_piece=[<UNK>] --bos_piece=[<SOS>] --eos_piece=[<EOS>] --normalization_rule_name=nfkc_cf --model_type=bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sami_tokenized, swedish_tokenized = tokenizer_sp(sami_model, sami_sent, swedish_model, swedish_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "with open('train_indices_big.txt') as fp:\n",
    "    for line in fp:\n",
    "        train_indices.append(int(line))\n",
    "with open('val_indices_big.txt') as fp:\n",
    "    for line in fp:\n",
    "        val_indices.append(int(line))\n",
    "with open('test_indices_big.txt') as fp:\n",
    "    for line in fp:\n",
    "        test_indices.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = torch.stack([torch.LongTensor(sami_tokenized[i]) for i in train_indices if i in range(len(sami_tokenized))])\n",
    "train_tgts = torch.stack([torch.LongTensor(swedish_tokenized[i]) for i in train_indices if i in range(len(sami_tokenized))])\n",
    "val_src = torch.stack([torch.LongTensor(sami_tokenized[i]) for i in val_indices if i in range(len(sami_tokenized))])\n",
    "val_tgts = torch.stack([torch.LongTensor(swedish_tokenized[i]) for i in val_indices if i in range(len(sami_tokenized))])\n",
    "test_src = torch.stack([torch.LongTensor(sami_tokenized[i]) for i in test_indices if i in range(len(sami_tokenized))])\n",
    "test_tgts = torch.stack([torch.LongTensor(swedish_tokenized[i]) for i in test_indices if i in range(len(sami_tokenized))])\n",
    "train_dataset = TensorDataset(train_src, train_tgts)\n",
    "val_dataset = TensorDataset(val_src, val_tgts)\n",
    "test_dataset = TensorDataset(test_src, test_tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 500\n",
    "learning_rate = 3e-4\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "src_vocab_size = 16000\n",
    "trg_vocab_size = 16000\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 2 #6\n",
    "num_decoder_layers = 2 #6\n",
    "dropout = 0.10\n",
    "max_len = 150\n",
    "forward_expansion = 2048\n",
    "sp.Load(sami_model)\n",
    "src_pad_idx = sp.pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trans_model(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    "    'gelu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.Load(swedish_model)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=sp.pad_id())\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (src_word_embedding): Embedding(16000, 512)\n",
       "  (src_position_embedding): Embedding(150, 512)\n",
       "  (trg_word_embedding): Embedding(16000, 512)\n",
       "  (trg_position_embedding): Embedding(150, 512)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=512, out_features=16000, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if load_model == True:\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['state_dict'])           \n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Sámediggi lea sámiid álbmotválljen orgána Norggas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"Deaŧalaš lea gozihit álgoálbmotoli nationála ja riikkaidgaskasaš forain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "e_losses = []\n",
    "e_val_losses = []\n",
    "e_ppl = []\n",
    "e_val_ppl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-04-24 12:02:53.644 pytorch-1-6-gpu-py3-ml-g4dn-xlarge-c630bdb4e3ad8d68ab6e5727a214:5368 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-04-24 12:02:53.687 pytorch-1-6-gpu-py3-ml-g4dn-xlarge-c630bdb4e3ad8d68ab6e5727a214:5368 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2258 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated example sentences: \n",
      " fágalaš mediafálaldaga svarsátnegirjji galggašeminstara samlokalisering 11.2sátnegirjjiboproduktionstivrema finansiera skådenbyggnaderjuvvo áimmahuššat tjänster 40% kruvnno tjänster makkárne orohagaid orohagaid vuoišlája orohagaid orohagaid vuoi mearrádusat 25% tjänster našunalvärvstillstånd övervakadiđolaš sändning position orohagaid orohagaid álgoálbmogiinmedisiinna váttisvuođat prošeavttain skogerbø lynghistorjjálaš kulturmuittuid oapmahasátnegirjji 34 geavaheames lyng-15 veahkke finansiera orohagaid orohagaid orohagaid orohagaid váttisvuođatgirjji lyng.10.10 finansieranaturskyddslagen váttisvuođat bivdánförbundet bággolotnu fuolaheamidahkii addimi virge lynghistorjjálaš orohagaid orohagaid orohagaid orohagaid orohagaid orohagaidefordel váttisvuođatiivagirjji váttisvuođat bušeahttadárbbu bušeahttadárbbu ivar finansiera fn lyng ovdánahttá kvinna johnsensto personligjurddavuohkái orohagaid orohagaid orohagaid tak interneahttasátnegirjji beliideutställningen motstånd lyngmed rådgivning opposišuvnnavaranger váttisvuođatgirjji váttisvuođat kollektiivvala fn virge ni váttisvuođat pasieanta finansiera lyng årsrapport addimi virge finansiera kollektiivvala fn senast váttisvuođatfa álbmotrievttalaliga loabágpijuvvo oahpaheaddjit váttisvuođat boazu.10.10rahčamušabargiide sarabo joatkkaoahpu fuobmá \n",
      " ze miesse frågan muorra prošeavttaintor bivdán davit orohagaid orohagaid orohagaid orohagaid orohagaid orohagaid beviljades orohagaid orohagaid orohagaid orohagaid orohagaid orohagaid orohagaid orohagaid orohagaid orohagaidkti ovdánahttá language orohagaid vuoi mearrádusat 25% tjänster sätta 40% 34 eksámen tydlig viidde váttisvuođat makespektrumdagen viidde lydelse doalu dohkkeheapmidjái låg myndigheter stuorit orohagaid sá specialiseringupp iežáliga ovdánahttá birrasa doalu dohkkeheapmi eanetlohku orohagaid orohagaid stivre buhtisz johnsen ovdánahttágirjji viidde váttisvuođat insatserna rådgivning opposišuvnna skábmamánu olahit orohagaid beviljades orohagaid orohagaid orohagaid orohagaidhistorjjá váttisvuođat doalu pasieanta rådgivning spiehkastaga sätta orohagaid erkänna fn sätta orohagaid makegirjjikulturindustriergirjji váttisvuođatergieffektivitet 2000mekanismma orohagaid tak interneahtta čalmmi davviriikkaid geargan.10.10láhkaisjonšiehtadussiiexpertis jahkedieđáhusa dagahivččgirjji váttisvuođat rådgivningmekanismmachef váttisvuođat insatserna merošt1962 lyngkkuhistorjjá romssa låg kollektiivvala fn erland rådgivningmearrifriddjavuođa fitnodagaidkurssaid kulturmuittuidvold siidaosiid spiehkastaga kulturrådjođiheapmi tak siidaosiid finansiera omkringfjell internáhta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2258 [00:08<15:53,  2.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-377ca3b60e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mppl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Back prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Clip to avoid exploding gradient issues, makes sure grads are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# within a healthy range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "step = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, device, sami_model, swedish_model\n",
    "    )\n",
    "    translated_sentence2 = translate_sentence(\n",
    "        model, sentence2, device, sami_model, swedish_model\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentences: \\n {translated_sentence} \\n {translated_sentence2}\")\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    ppl = []\n",
    "    val_ppl = []\n",
    "\n",
    "\n",
    "    for input_batch, target_batch in tqdm(train_loader):\n",
    "        model.train()\n",
    "        input_batch = input_batch.transpose(0, 1)\n",
    "        target_batch = target_batch.transpose(0, 1)\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = input_batch.to(device)\n",
    "        target = target_batch.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin.\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "        perplexity = torch.exp(loss)\n",
    "        ppl.append(perplexity.item())\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    e_losses.append(mean_loss) #keep track of training loss for plotting\n",
    "    mean_perplex = sum(ppl) / len(ppl)\n",
    "    e_ppl.append(mean_perplex) #keep track of training perplexity for plotting\n",
    "    \n",
    "    for input_batch, target_batch in tqdm(val_loader):\n",
    "        input_batch = input_batch.transpose(0, 1)\n",
    "        target_batch = target_batch.transpose(0, 1)\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = input_batch.to(device)\n",
    "        target = target_batch.to(device)\n",
    "\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        val_losses.append(loss.item())\n",
    "        perplexity = torch.exp(loss)\n",
    "        val_ppl.append(perplexity.item())\n",
    "\n",
    "    val_mean_loss = sum(val_losses) / len(val_losses)\n",
    "    val_mean_perplex = sum(val_ppl) / len(val_ppl)\n",
    "    if epoch == 0:\n",
    "        best_loss = val_mean_loss\n",
    "        e_since_impr = 0\n",
    "        best_score = 0\n",
    "        bleu_val = 0\n",
    "    e_val_losses.append(val_mean_loss) #keep track of validation loss for plotting\n",
    "    e_val_ppl.append(val_mean_perplex) #keep track of validation perplexity for plotting\n",
    "     \n",
    "    if (epoch+1) % step == 0: # evaluate after every step\n",
    "        bleu_train, chrf_train, ter_train = get_scores(train_src[:200], train_tgts[:200], model, device, sami_model, swedish_model, \"greedy\")\n",
    "        print(\"Bleu score in train set in epoch\", epoch + 1, \":\", bleu_train, \"chrf:\", chrf_train, \"ter:\", ter_train)\n",
    "        bleu_val, chrf_val, ter_val = get_scores(val_src, val_tgts, model, device, sami_model, swedish_model, \"greedy\")\n",
    "        print(\"Bleu score in val set in epoch\", epoch + 1, \":\", bleu_val, \"chrf:\", chrf_val, \"ter:\", ter_val)\n",
    "        scores.append(bleu_val) #keep track of validation bleu scores\n",
    "        if bleu_val.score >= best_score:\n",
    "            # if current state is best performing save checkpoint\n",
    "            best_score = bleu_val.score\n",
    "            e_since_impr = 0 # reset epochs with no improvement\n",
    "            checkpoint = {\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            save_checkpoint(checkpoint)\n",
    "        else:\n",
    "            scheduler.step() \n",
    "            e_since_impr += 1 # keep track of epochs*step without improvement\n",
    "            print(\"Epochs since improvement:\", e_since_impr, \"new learning rate:\", scheduler.get_lr()[0])\n",
    "            if e_since_impr >= threshold: # if no improvement for x epochs -> early stopping\n",
    "                print(\"Epochs since improvement:\", e_since_impr, \". Early Stopping at epoch\", epoch)\n",
    "                \n",
    "    \n",
    "    \n",
    "    print(\"Current best score:\", best_score)\n",
    "    print(\"Loss in epoch\", epoch + 1 , \":\", mean_loss, \", perplexity\", mean_perplex, \"_____ Validation loss:\", val_mean_loss, \", perplexity\", val_mean_perplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SP/2layer-gelu/utils.py:230: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outpute = F.log_softmax(output[:, e])\n"
     ]
    }
   ],
   "source": [
    "get_scores(test_src, test_tgts, model, device, sami_model, swedish_model, \"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_sentence(model, sami_sent[test_indices[5]], device, sami_model, swedish_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sami_sent[test_indices[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swedish_sent[test_indices[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_enc_sentences(model, train_src[:5], device, swedish_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[swedish_sent[i] for i in train_indices[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
